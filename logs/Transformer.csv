epoch,train_loss,test_loss
1,4321.152793884277,343.4017667770386
2,1531.3770236968994,374.35868644714355
3,1111.51042842865,283.2810001373291
4,920.7141275405884,282.8559522628784
5,901.8827533721924,274.1141300201416
6,827.8503332138062,246.71812629699707
7,861.982668876648,264.4228353500366
8,826.154034614563,231.26957416534424
9,802.3609781265259,236.5360050201416
10,774.5551099777222,239.65851402282715
11,785.7483787536621,225.76240634918213
12,781.6360149383545,229.36709880828857
13,773.2587604522705,230.6225152015686
14,735.5380935668945,253.6172046661377
15,757.1182117462158,226.37249851226807
16,733.5314507484436,218.69394826889038
17,748.4867362976074,225.79166412353516
18,751.3993945121765,221.53830337524414
19,729.2816638946533,223.31764030456543
20,715.7134294509888,233.57984066009521
21,725.9467878341675,232.07444190979004
22,729.5572004318237,229.93760299682617
23,723.9920644760132,227.11779499053955
24,742.2751755714417,223.1381893157959
25,727.5367240905762,217.58810234069824
26,713.8272109031677,221.06059789657593
27,712.9892477989197,221.96035957336426
28,706.3318886756897,218.88630723953247
29,719.7824640274048,216.87201499938965
30,699.3883285522461,218.86782264709473
31,702.0356540679932,242.39677906036377
32,731.6541709899902,222.12332201004028
33,696.8040699958801,218.53496646881104
34,705.9672050476074,224.5009412765503
35,725.3875780105591,219.53778457641602
36,707.877673625946,224.55452251434326
37,702.555016040802,221.20950174331665
38,696.3760437965393,212.26237630844116
39,705.8854074478149,219.81527519226074
40,690.8141598701477,222.63140487670898
41,698.0571236610413,216.75748109817505
42,685.1416163444519,220.97077178955078
43,688.6040945053101,223.42439889907837
44,687.0248599052429,214.2641258239746
45,675.6843457221985,219.3795166015625
46,706.960901260376,227.67461395263672
47,716.3351883888245,226.89319515228271
48,704.8618936538696,211.58820962905884
49,678.769190788269,215.40507745742798
50,682.9982104301453,215.37672519683838
